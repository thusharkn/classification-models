{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39211 entries, 0 to 39210\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   last contact date  39211 non-null  object\n",
      " 1   age                39211 non-null  int64 \n",
      " 2   job                38982 non-null  object\n",
      " 3   marital            39211 non-null  object\n",
      " 4   education          37744 non-null  object\n",
      " 5   default            39211 non-null  object\n",
      " 6   balance            39211 non-null  int64 \n",
      " 7   housing            39211 non-null  object\n",
      " 8   loan               39211 non-null  object\n",
      " 9   contact            28875 non-null  object\n",
      " 10  duration           39211 non-null  int64 \n",
      " 11  campaign           39211 non-null  int64 \n",
      " 12  pdays              39211 non-null  int64 \n",
      " 13  previous           39211 non-null  int64 \n",
      " 14  poutcome           9760 non-null   object\n",
      " 15  target             39211 non-null  object\n",
      "dtypes: int64(6), object(10)\n",
      "memory usage: 4.8+ MB\n",
      "None\n",
      "\n",
      "Test Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   last contact date  10000 non-null  object\n",
      " 1   age                10000 non-null  int64 \n",
      " 2   job                9941 non-null   object\n",
      " 3   marital            10000 non-null  object\n",
      " 4   education          9610 non-null   object\n",
      " 5   default            10000 non-null  object\n",
      " 6   balance            10000 non-null  int64 \n",
      " 7   housing            10000 non-null  object\n",
      " 8   loan               10000 non-null  object\n",
      " 9   contact            7316 non-null   object\n",
      " 10  duration           10000 non-null  int64 \n",
      " 11  campaign           10000 non-null  int64 \n",
      " 12  pdays              10000 non-null  int64 \n",
      " 13  previous           10000 non-null  int64 \n",
      " 14  poutcome           2492 non-null   object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4097/3522003536.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train[col].fillna(train[col].mode()[0], inplace=True)\n",
      "/tmp/ipykernel_4097/3522003536.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test[col].fillna(test[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'target'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m categorical_cols:\n\u001b[1;32m     32\u001b[0m     train[col]\u001b[38;5;241m.\u001b[39mfillna(train[col]\u001b[38;5;241m.\u001b[39mmode()[\u001b[38;5;241m0\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 33\u001b[0m     \u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mfillna(test[col]\u001b[38;5;241m.\u001b[39mmode()[\u001b[38;5;241m0\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Pipeline components for preprocessing\u001b[39;00m\n\u001b[1;32m     36\u001b[0m label_encoders \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'target'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# --- 1. Load and Explore the Data ---\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "print(\"Train Data Info:\")\n",
    "print(train.info())\n",
    "print(\"\\nTest Data Info:\")\n",
    "print(test.info())\n",
    "\n",
    "# --- 2. Feature Engineering and Preprocessing ---\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = train.select_dtypes(include=['object']).columns\n",
    "numerical_cols = train.select_dtypes(include=np.number).columns\n",
    "\n",
    "# Handle missing values\n",
    "train = train.fillna(train.median(numeric_only=True))\n",
    "test = test.fillna(test.median(numeric_only=True))\n",
    "\n",
    "for col in categorical_cols:\n",
    "    train[col].fillna(train[col].mode()[0], inplace=True)\n",
    "    test[col].fillna(test[col].mode()[0], inplace=True)\n",
    "\n",
    "# Pipeline components for preprocessing\n",
    "label_encoders = {}\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('label_encoding', 'passthrough')  # Label encoding happens dynamically below\n",
    "])\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaling', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply LabelEncoder dynamically for categorical columns\n",
    "for col in categorical_cols:\n",
    "    if col != 'target':\n",
    "        le = LabelEncoder()\n",
    "        train[col] = le.fit_transform(train[col])\n",
    "        label_encoders[col] = le\n",
    "        test[col] = test[col].apply(lambda x: le.transform([x])[0] if x in le.classes_ else -1)\n",
    "\n",
    "# --- 3. Prepare Training and Validation Data ---\n",
    "X_train = train.drop('target', axis=1)\n",
    "y_train = train['target'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- 4. Build the LightGBM Pipeline ---\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LGBMClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=-1,  # No depth limit\n",
    "        min_data_in_leaf=20,  # Prevent overfitting\n",
    "        min_gain_to_split=0.1,  # Minimum gain required to split\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# --- 5. Train the Model ---\n",
    "pipeline.fit(X_train_split, y_train_split)\n",
    "y_lgbm_pred = pipeline.predict(X_val_split)\n",
    "\n",
    "# --- 6. Evaluate the Model ---\n",
    "print(\"\\n--- LightGBM Results ---\")\n",
    "print(f\"Validation F1 Score (macro): {f1_score(y_val_split, y_lgbm_pred, average='macro')}\")\n",
    "print(classification_report(y_val_split, y_lgbm_pred))\n",
    "\n",
    "# Confusion matrix visualization\n",
    "cm = confusion_matrix(y_val_split, y_lgbm_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - LightGBM\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# --- 7. Hyperparameter Tuning ---\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'classifier__min_gain_to_split': [0.0, 0.1, 0.2],\n",
    "    'classifier__min_data_in_leaf': [20, 50, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, scoring='f1_macro', cv=3)\n",
    "grid_search.fit(X_train_split, y_train_split)\n",
    "\n",
    "print(\"\\n--- Best Parameters for LightGBM ---\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# --- 8. Final Predictions ---\n",
    "X_test = test.copy()\n",
    "submission = pd.DataFrame({'id': range(len(X_test)), 'target': pipeline.predict(X_test)})\n",
    "submission.to_csv('submission_lgbm_pipeline.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
